The LLM app allows users to deploy machine learning models using [text-generation-inference](https://github.com/huggingface/text-generation-inference) as a model serving backend and [gradio](https://github.com/gradio-app/gradio) as a web interface.