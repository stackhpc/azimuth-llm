azimuth-llm:
  huggingface:
    # Use the smallest vision model we can find
    model: &model HuggingFaceTB/SmolVLM-256M-Instruct
  api:
    # CI Kind cluster doesn't have kube-prometheus-stack
    monitoring:
      enabled: false
    # No GPUs in CI runners
    gpus: 0
  ui:
    service:
      zenith:
        enabled: false
    appSettings:
      model_name: *model
      # Verify that we can set non-standard LLM params
      llm_params:
        max_tokens: 10 # Constrain response tokens to speed up CI test
        temperature: 0.1
        top_p: 0.15
        presence_penalty: 0.9
        frequency_penalty: 1
