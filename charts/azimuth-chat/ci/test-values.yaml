azimuth-llm:
  huggingface:
    # Use the smallest LLM we can find
    model: HuggingFaceTB/SmolLM2-135M-Instruct
  api:
    # CI Kind cluster doesn't have kube-prometheus-stack
    monitoring:
      enabled: false
    # No GPUs in CI runners
    gpus: 0
  ui:
    service:
      zenith:
        enabled: false
    appSettings:
      # Verify that we can set non-standard LLM params
      llm_params:
        max_tokens: 101
        temperature: 0.1
        top_k: 2
        top_p: 0.15
        presence_penalty: 0.9
        frequency_penalty: 1
